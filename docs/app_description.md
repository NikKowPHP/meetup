# **EventFlow: Technical Application Description (v2 - Robust)**

## 1. Vision & Architectural Philosophy

**EventFlow** is a Progressive Web App (PWA) conceived as the definitive, mobile-first hub for city-wide event discovery. Our architecture prioritizes a **resilient and self-healing data pipeline**, end-to-end type-safety, and a seamless PWA experience that eradicates the friction of modern event-seeking.

The core philosophy is to **transform a fragmented digital landscape into a unified, actionable experience**. We recognize that the value of a city is in its happenings, yet discovering them is a chore. EventFlow acts as the central nervous system for local culture, commerce, and community, ingesting data from disparate sources and presenting it through a single, elegant interface.

Our monetization model is built on providing clear value to both sides of the marketplace. The core discovery experience is **always free** for users, ensuring maximum audience reach. Revenue is generated by providing event organizers with powerful, optional tools to amplify their reach, creating a symbiotic relationship that funds the platform's growth and keeps the core service accessible to all.

## 2. Architectural Overview

The system is designed around a clean separation of concerns within a Next.js monorepo. This approach uses server components for a performant frontend, API routes for backend logic, and separate, robust serverless functions for the data aggregation pipeline, complete with retries and failure monitoring.

```mermaid
graph TD
    subgraph User Device
        A[PWA on Browser/Mobile]
    end

    subgraph Vercel/Hosting
        B(Next.js App)
        B -- Serves UI --> A
        B -- API Routes --> C
    end

    subgraph Backend Services
        C{EventFlow API (Next.js API Routes)}
        D[Supabase Auth]
        E[Supabase Storage Bucket]
        F[PostgreSQL DB (via Prisma)]
        G[Stripe API]
        K[Firebase Cloud Messaging (FCM)]
    end

    subgraph Content Aggregation Pipeline (Job Queue System)
        H[node-schedule] -- "1. Schedules Jobs" --> I{BullMQ Queue}
        I -- "2. Distributes to Workers" --> J[Scraper Workers]
        J -- "3. Scrapes (with Retries)" --> K[External Event Sites]
        J -- "4. On Failure: Log & Alert" --> L[Sentry Error Tracking]
        J -- "5. On Success: Normalize & Save Data" --> F
    end

    %% User Facing Flows
    A -- "Signs In/Up" --> D
    A -- "Views Events, Filters Map" --> C
    A -- "Subscribes to Notifications" --> C
    A -- "Purchases Promotion/Subscription" --> G
    A -- "Claims an Event" --> C

    %% Backend System Flows
    C -- "Verifies User JWT" --> D
    C -- "CRUD (Events, RSVPs, Claims)" --> F
    C -- "Manages Subscriptions & Payments" --> G
    C -- "Dispatches Push Notifications" --> K
    C -- "Stores Push Subscription" --> F
```

**Flow Description:**
1.  **Content Aggregation (Job Queue):** The `node-schedule` library triggers jobs at scheduled intervals, which are added to a `BullMQ` (Redis) queue. Worker processes pull jobs from the queue and execute the scraping tasks with built-in **retry mechanisms and exponential backoff** for transient errors. Failed jobs are automatically retried according to the queue configuration, and critical failures are logged to Sentry for alerting. This architecture provides better resilience and scalability for long-running background tasks.
2.  **Client (PWA):** The user interacts with the Next.js frontend, rendered server-side for optimal performance and SEO. The Supabase client-side library handles authentication directly and securely.
3.  **Application Backend (Next.js API Routes):** Core business logic resides here. API routes, protected by JWT verification, handle data retrieval, manage user actions (joining/claiming events), process payments, and trigger push notifications via FCM.
4.  **Payment Processing:** Stripe handles B2B event promotion purchases and B2C premium subscriptions. A dedicated, secure webhook endpoint, which validates incoming Stripe signatures, listens for Stripe events to update the database in real-time.

## 3. Core Tech Stack

| Component | Technology | Rationale |
| :--- | :--- | :--- |
| **Framework** | **Next.js 15+ (App Router)** | Unified full-stack development, perfect for building a performant, SEO-friendly PWA. |
| **Database** | **PostgreSQL** | Robust, scalable, and offers the powerful **PostGIS extension** for highly efficient geospatial queries, critical for our map-based discovery. |
| **ORM** | **Prisma** | Provides end-to-end type-safety from our database to our application, simplifying queries and preventing entire classes of bugs. |
| **Auth & Storage** | **Supabase (Auth & Storage)**| Offloads complex user management and file storage, providing secure, scalable SDKs. |
| **Payments** | **Stripe** | Industry leader for both one-time payments (Checkout) and recurring billing (Subscriptions). |
| **Push Notifications**| **Firebase Cloud Messaging (FCM)** | Provides a reliable, free service to deliver push notifications to web clients (PWAs) across all major platforms. |
| **Web Scraping** | **Puppeteer / Cheerio** | A combination of a headless browser for dynamic sites and a lightweight parser for static sites, wrapped in robust error-handling logic. |
| **Mapping** | **Mapbox GL JS / React Map GL** | High-performance, customizable, and mobile-friendly vector maps, essential for the core user experience. |
| **Job Scheduling** | **BullMQ & node-schedule** | Robust queue system with Redis backend for handling resilient, long-running background tasks, combined with node-schedule for precise timing control. |
| **Styling** | **Tailwind CSS + shadcn/ui** | Utility-first CSS for rapid UI development with unstyled, accessible components. |
| **Deployment** | **Vercel** | Premier hosting for Next.js, offering seamless CI/CD, serverless functions, and integrated cron jobs. |

## 4. Monetization Strategy: Dual B2B & B2C

The platform leverages a dual-revenue model to sustain growth while keeping the core product free. To facilitate the B2B model, a secure **"Claim Your Event"** workflow will allow organizers to verify ownership of scraped events and gain access to promotional tools. Stripe handles all payment processing.

### **Primary: Event Promotion (B2B)**
A self-service portal for event organizers to purchase premium visibility for their events.

*   **Offerings:** Featured placements on the homepage, top of category searches, and map highlights.
*   **Implementation:** Verified organizers use **Stripe Checkout** for simple, one-time payments. A webhook updates the event's `isFeatured` flag in the database.

### **Secondary: Premium User Subscriptions (B2C)**
A freemium model for power users who want an enhanced experience.

| Tier | Price | Key Features | Target |
| :--- | :--- | :--- | :--- |
| **Free** | $0 | Core discovery (map/list view), advanced search & filtering, personal calendar (attending). | All users for acquisition and building a critical mass. |
| **Pro** | ~$3-5 / month | All Free features, plus:<br>• **Custom Notifications** (for keywords, venues)<br>• **Ad-free experience**<br>• Unlimited external calendar sync<br>• Access to curated event lists | Dedicated users seeking to maximize their local experience. |

## 5. High-Level Prisma Schema

```prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider  = "postgresql"
  url       = env("DATABASE_URL")
}

model User {
  id                 String              @id @default(uuid())
  email              String              @unique
  name               String?
  supabaseAuthId     String              @unique @map("supabase_auth_id")
  stripeCustomerId   String?             @unique @map("stripe_customer_id")
  subscriptionTier   String              @default("FREE")
  createdAt          DateTime            @default(now()) @map("created_at")
  updatedAt          DateTime            @updatedAt @map("updated_at")
  
  organizedEvents    Event[]             @relation("EventOrganizer")
  eventsAttending    UserAttendingEvent[]
  eventClaimRequests EventClaimRequest[]
  pushSubscriptions  PushSubscription[]
}

model Event {
  id              String      @id @default(cuid())
  title           String
  description     String      @db.Text
  startTime       DateTime    @map("start_time")
  endTime         DateTime?   @map("end_time")
  venueName       String?     @map("venue_name")
  address         String?
  latitude        Float?
  longitude       Float?
  sourceUrl       String      @map("source_url")
  imageUrl        String?     @map("image_url")
  isFree          Boolean     @default(true) @map("is_free")
  isFeatured      Boolean     @default(false) @map("is_featured")
  status          String      @default("DRAFT") // DRAFT, PUBLISHED, FLAGGED, PENDING_CLAIM
  createdAt       DateTime    @default(now()) @map("created_at")
  updatedAt       DateTime    @updatedAt @map("updated_at")

  organizerId     String?     @map("organizer_id")
  organizer       User?       @relation("EventOrganizer", fields: [organizerId], references: [id])
  
  categoryId      String?
  category        Category?   @relation(fields: [categoryId], references: [id])
  
  attendees       UserAttendingEvent[]
  promotions      Promotion[]
  claimRequests   EventClaimRequest[]

  @@index([startTime, status])
  @@index([latitude, longitude]) // Add PostGIS index via raw migration later
}

model Category {
  id     String  @id @default(cuid())
  name   String  @unique
  events Event[]
}

model UserAttendingEvent {
  userId    String
  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  eventId   String
  event     Event    @relation(fields: [eventId], references: [id], onDelete: Cascade)
  createdAt DateTime @default(now())

  @@id([userId, eventId])
}

model EventClaimRequest {
  id                String   @id @default(cuid())
  userId            String
  user              User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  eventId           String
  event             Event    @relation(fields: [eventId], references: [id], onDelete: Cascade)
  status            String   @default("PENDING") // PENDING, APPROVED, REJECTED
  verificationToken String?  @unique @map("verification_token")
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt
  
  @@unique([userId, eventId])
}

model Promotion {
  id             String    @id @default(cuid())
  eventId        String
  event          Event     @relation(fields: [eventId], references: [id], onDelete: Cascade)
  stripeChargeId String    @unique @map("stripe_charge_id")
  promotionTier  String    @map("promotion_tier")
  expiresAt      DateTime  @map("expires_at")
  createdAt      DateTime  @default(now()) @map("created_at")
}

model PushSubscription {
  id        String   @id @default(cuid())
  userId    String
  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  endpoint  String   @unique
  keys      Json
  createdAt DateTime @default(now()) @map("created_at")
}
```

## 6. Development Epics & User Stories

### **Epic 1: Automated Content Aggregation**
*   **EF-001: Scrape Static Site:** As the system, I can scrape event data from a simple, HTML-based source with robust error handling.
*   **EF-002: Scrape Dynamic Site:** As the system, I can use a headless browser to scrape data from a JavaScript-rendered site, with retries on failure.
*   **EF-003: Deduplicate Events:** As the system, I can identify and avoid inserting duplicate events based on a composite key (e.g., title, date, source URL).

### **Epic 2: Core User Experience (Free)**
*   **EF-010: View Events on Map:** As a user, I can see events plotted as pins on an interactive map.
*   **EF-011: Filter Events:** As a user, I can filter events by category, date, and free/paid status.
*   **EF-012: View Event Details:** As a user, I can click an event to see its full details, including a prominent link to the original source.
*   **EF-013: Join an Event:** As a user, I can click "Join" to add an event to my personal calendar within the app.

### **Epic 3: User Onboarding & Authentication**
*   **EF-020: Account Creation:** As a user, I can register for an account using my email or a social provider.
*   **EF-021: User Login:** As a user, I can log in and out of my account.
*   **EF-022: View Personal Calendar:** As a logged-in user, I can view a page listing all events I have "Joined".
*   **EF-023: Delete Account:** As a user, I can permanently delete my account and all associated data through a settings page.

### **Epic 4: Organizer Event Management & Verification**
*   **EF-030: Initiate Event Claim:** As a logged-in user, I can find my event and click a "Claim this Event" button.
*   **EF-031: Verify Ownership:** As a user who has initiated a claim, I receive an email with a verification link to prove I am the organizer.
*   **EF-032: Manage Claimed Events:** As a verified organizer, I see a dashboard of my claimed events where I can access promotional tools.
*   **EF-ADM-004: Review Claim Requests:** As an Admin, I can view and manually approve/reject event claim requests in cases of dispute.

### **Epic 5: Organizer Monetization (B2B)**
*   **EF-040: View Promotion Options:** As a verified organizer, I can see a clear "Promote Event" option on my claimed event's dashboard.
*   **EF-041: Purchase Promotion:** As an organizer, I can pay for a featured listing via a secure Stripe Checkout session.
*   **EF-042: See Featured Event:** As a user, I can see "Featured" events displayed with special prominence.

### **Epic 6: Premium User Subscriptions (B2C)**
*   **EF-050: Subscribe to Pro:** As a free user, I can upgrade to the Pro tier via Stripe.
*   **EF-051: Create Custom Notification:** [Premium] As a Pro user, I can set up a notification for a specific keyword (e.g., "karaoke").
*   **EF-052: Manage Subscription:** As a Pro user, I can manage my subscription via the Stripe Customer Portal.

### **Epic 7: Admin Curation & Analytics**
*   **EF-ADM-001: Draft Review Dashboard:** As an Admin, I can view a list of all newly scraped events in "DRAFT" status.
*   **EF-ADM-002: Edit & Approve Events:** As an Admin, I can edit event details and change its status to "PUBLISHED."
*   **EF-ADM-003: View Key Metrics:** As an Admin, I can see a dashboard with key metrics like users, events ingested, and top categories to monitor platform health.

## 7. Development & Compliance Practices

### 7.1. UI/UX: Mobile-First Responsive Design
The application will be built mobile-first. All UI will be designed for the smallest viewport first, then progressively enhanced for larger screens using Tailwind CSS.

### 7.2. Code Quality & Best Practices
*   **Folder Structure:** We will use a feature-sliced structure (e.g., `src/features/event-map`) to promote modularity and developer velocity.
*   **Component Scoping:** We will default to Server Components, opting into Client Components (`"use client"`) only for interactive elements.
*   **End-to-End Type Safety:** `TypeScript`, `Prisma`, and `Zod` will ensure data is strongly typed from the database to the UI.
*   **Scraping Ethics & Robustness:** All scrapers will respect `robots.txt`, operate at a respectful rate, and clearly attribute the source. They will be wrapped in resilient error-handling logic with automated retries.

### **Security Model**
The application implements a granular Role-Based Access Control (RBAC) system to manage permissions across different user types. The system, defined in `lib/auth/rbac.ts`, supports the following roles:

* **ADMIN**: Full access to all administrative functions including event curation, claim approvals, and system settings
* **MODERATOR**: Can moderate content and manage reported issues, but cannot change system settings
* **USER**: Standard authenticated users with permissions to create, join, and manage their own events
* **GUEST**: Limited read-only access for unauthenticated users

The RBAC system integrates with Next.js middleware to enforce permissions at both the UI and API levels.

### 7.3. Observability Strategy
*   **Error Tracking:** **Sentry** will be integrated to capture all unhandled exceptions and will be configured with **high-priority alerts for any scraper function failures**.
*   **Performance Monitoring:** **Vercel Analytics** will be used to monitor Core Web Vitals and overall site performance.
*   **Structured Logging:** The Content Aggregation Pipeline will use **structured logging** (e.g., JSON format) to provide a clear, traceable record of each run, including a run ID, number of events attempted, successes, failures, and reasons for failure.

### 7.4. Legal & Data Privacy
*   **Privacy by Design:** The application will be built with user privacy as a core consideration.
*   **Compliance:** We will provide a clear and accessible **Privacy Policy** and **Terms of Service**. User consent will be explicitly obtained for data processing and cookie usage, in line with GDPR/CCPA best practices.
*   **Data Minimization:** We will only collect user data that is essential for the functioning of the service.

## 8. MVP Scope & Phasing

### Phase 1: MVP (Target: Initial Launch)
*   **Focus:** Validate the core loop of aggregation, discovery, and the B2B monetization flow. Quality and robustness are key.
*   **Epics to be Completed:** Epic 1 (Aggregation for 2-3 key sources), Epic 2 (Core UX), Epic 3 (Auth), **Epic 4 (Event Claim Workflow)**, **Epic 5 (B2B Promotions)**, and Epic 7 (Admin Curation Dashboard is critical for quality control).

### Phase 2: Post-MVP (First Major Update)
*   **Focus:** Enhance the user experience and introduce the B2C revenue stream.
*   **Epics to be Implemented:** Epic 6 (Premium Subscriptions), expand sources for Epic 1, and implement PWA push notifications.

## 9. Potential Risks & Mitigation

| Risk Category | Risk Description | Mitigation Strategy |
| :--- | :--- | :--- |
| **Technical** | Source website layouts change, breaking the scrapers. | **Proactive Monitoring & Modularity:** Use Sentry for instant alerts on scraper failures. Build scrapers as independent modules, so a single failure doesn't halt the entire pipeline. The Admin dashboard will serve as a final quality gate. |
| **Technical** | Scraper function execution time exceeds serverless limits (e.g., 60s on Vercel). | **Architectural Foresight:** Monitor function duration via Vercel logs. For a future phase, plan to migrate long-running jobs to a dedicated queue-based system (e.g., BullMQ on Railway, Google Cloud Tasks) that is designed for such workloads. |
| **Technical** | IP address is blocked by a source site due to scraping activity. | **Phased Approach:** Initially, scrape at a respectful rate. If blocking becomes an issue, integrate a third-party proxy/IP rotation service (e.g., Bright Data, ScraperAPI) as a next step. |
| **Legal/Ethical**| Event sources block our scrapers or raise copyright/ToS concerns. | **Good Faith & Attribution:** Strictly adhere to `robots.txt`, always provide a prominent canonical link back to the source, and make the "Claim Your Event" and "Request Removal" processes simple and visible. |
| **Product** | The B2B promotion model fails to attract paying event organizers. | **Value First:** The "Claim Your Event" workflow (Epic 4) is the first step to building a relationship. Focus on building a large, engaged free user base to create a valuable audience that organizers will want to pay to reach. |